Proszę wyjaśnić znaczenie pojęcia TCO.;Total Cost of Ownership - całkowity koszt posiadania oprogramowania. Suma kosztów nabycia, wdrożenia, utrzymania i użytkowania przez cały okres jego życia. \nkoszty bezpośrednie (w trakcie developmentu): licencje, wdrożenia, szkolenia, infrastruktura (serwery) \nkoszty pośrednie (po wydaniu): utrzymanie (aktualizacje, support), koszty awarii, koszty wycofania \n oczywiście jak koszty okresowe to mnożymy przez czas;1
Proszę podać trzy przykłady metryki oprogramowania.;LOC - Lines of Code - nie odzwierciedla jakości\nCyclomatic Complexity (złożoność cyklomatyczna) - Mierzy liczbę niezależnych ścieżek przez kod - wysoka wartość może wskazywać na dużą złożoność, a to źle\nŚredni czas pracy bezawaryjnej (MTTF)) - średni czas, przez jaki system działa poprawnie bez awarii;1
Proszę podać definicję estymacji projektu.;Oszacowanie ilościowe nieznanych wielkości parametrów zadania na podstawie zdefiniowanego zakresu prac oraz ogólnej wiedzy o warunkach realizacji projektu.\nEstymacja ma charakter probabilistyczny, posiada pewien poziom ufności i silnie zależy od przyjętych założeń.\nNajbardziej optymistyczna prognoza o niezerowym prawdopodobieństwie spełnienia.;1
Proszę opisać modelowy proces estymacji projektu.;1. Wymagania wobec oprogramowania - zebranie i analiza wymagań funkcjonalnych i niefunkcjonalnych\n2. Wielkość oprogramowania - określa się rozmiar systemu – np. w punktach funkcyjnych, liniach kodu, przypadkach użycia.\n3. Nakład pracy + koszty pośrednie - Rozmiar systemu przelicza się na: liczbę roboczogodzin, liczbę osób potrzebnych do realizacji, koszty pracy i koszty ogólne (np. infrastruktura, szkolenia, komunikacja).\n4. Czas trwania / harmonogram - estymuje się: czas potrzebny do wykonania projektu, podział na etapy, terminy realizacji.;1
Proszę wymienić negatywne czynniki zawyżonego oszacowania.;Prawo Parkinsona – realizacja zadania zawsze wypełnia cały dostępny czas i dostępne zasoby\nSyndrom studenta – zwlekanie na ostatnią chwilę z rozpoczęciem zadania\nKierownik typu X – pracownicy są nieodpowiedzialni, okłamują szefów, zawyżają oszacowania i wymagają ciągłej kontroli;1
Proszę wymienić negatywne czynniki zaniżonego oszacowania.;Dług technologiczny\nBrak możliwości rzeczywistego zaplanowania prac w projekcie\nMniejsze prawdopodobieństwo na terminowe wykonanie projektu\n„Ucinanie kantów” na szkoleniu, dokumentacji, projekcie technicznym prowadzi do zmniejszenia jakości produktu\nDodatkowe czynności i zasoby związane z gaszeniem pożaru (spotkania, eskalacje, raporty, wersje beta, itd.)\nUcieczka pracowników wykwalifikowanych i znających problematykę;1
Co zyskujemy poprawiając dokładność oszacowania w projekcie?;Możliwość lepszego zaplanowania zadań w projekcie\n Osiągnięcie planowanej jakości\n Zdecydowanie lepsze zarządzanie budżetem projektu – system motywacyjny\n Uznanie dla profesjonalizmu zespołu projektowego\n Możliwość planowania kolejnych projektów\n Dobre relacje z klientem – lepsze perspektywy na kolejne kontrakty;1
Proszę wymienić główne błędy metod estymacji.;Brak odniesienia do poprzednich projektów\nStosowanie tylko jednej metody bez możliwości weryfikacji z wynikami innych metod\nBrak ciągłego uaktualniania estymacji i porównania z rzeczywistymi wielkościami po zakończeniu projektu\nBrak stosowania jakiejkolwiek metody estymacji\nSzacowanie w celu dostosowania wielkości do oczekiwań sponsora projektu, klienta, udziałowców, „price to win” itd.;1
Proszę wymienić główne błędy społeczne estymacji.;Nadmierny optymizm w stosunku do dostępności i kompetencji zespołu projektowego\nPrzecenianie wpływu narzędzi i nowych technologii\nBrak odniesieni do krzywej uczenia się zespołu projektowego\nUtajnianie złych informacji przed przełożonymi;1
Proszę wymienić główne błędy organizacyjne estymacji.;Brak doświadczonych kierowników projektów\nRozproszenie odpowiedzialności w strukturze organizacyjnej, brak jasnych ścieżek raportowania\nRozproszenie zespołu projektowego\nNieodpowiednie narzędzia i technologia;1
Proszę wyjaśnić pojęcie stożka niepewności. + jak wygląda;Gdy szacujemy jednopuktowo (co to?) stosowane są przediały niepewności prefiniowane dla poszczególnych etapów projektu. \nGdy się te przediały narusyje na wykresie wychodzi stożek. (x=czas, y=błąd oszacowania)\nWtedy podstawa stożka jest na osi y. Początek projektu jest przy podstawie, a koniec przy wierzchołku\nOś symetrii stożka wypada dla y=1;2
Proszę opisać zjawisko eksplozji wymagań. Jaki wpływ ma to zjawisko na dokładność oszacowań w projekcie?;Eksplozja wymagań - znaczny wzrost liczby wymagań w projekcie w miarę jego trwania\nI wtedy stożek przestaje być stożkiem - na górze robi mu się bulge, co oznacza że taski nagle zajmują więcej czasu niż jest planowane;2
Proszę opisać proces planowania projektu.;1. Dekompozycja zadań w projekcie\n2. Identyfikacja i zdefiniowanie aktywności + dokładny opis\n3. Stworzenie diagramu sieciowego - Ustalenie zależności między aktywnościami - mozemy je uporządkować.\n4. (symultanicznie z 5) Estymacja długości trwania aktywności\n5. (symultanicznie z 4) Estymacja wymaganych zasobów (ludzkich, sprzętowych, materiałowych)\n6. Stworzenie harmonogramu\n7. Ustalenie wartości bazowych planu projektu;2
Proszę wyjaśnić pojęcie WBS.;WBS - Work Breakdown Structure struktura podziału pracy - hierarchiczny podział projektu na mniejsze, łatwe do zarządzania elementy (pakiety prac). Ułatwia planowanie, przypisywanie zasobów i kontrolę realizacji.;2
Proszę wymienić i wyjaśnić różnice znanych typów WBS.;1. WBS funkcjonalny (procesowy) - Podział wg działań lub funkcji - co trzeba zrobić? (działania które trzeba podjąć)\n2. WBS produktowy - Podział wg komponentów produktu - co trzeba dostarczyć? (rezultaty, komponentów końcowego produktu)\n3. WBS mieszany (hybrydowy) - Łączy elementy funkcjonalne i produktowe.;2
Proszę opis reguły stosowane podczas tworzenia WBS.;1. Zasada 100% – WBS musi obejmować 100% zakresu projektu, bez pominięć ani powtórzeń.\n2. Hierarchiczność – WBS ma strukturę drzewa\n3. Dekompozycja do poziomu pakietu pracy – podział trwa, aż uzyskamy element możliwy do przypisania, oszacowania i kontrolowania.\n4. Brak nakładania się zakresów elementów wbs.\n5. Spójność i jednolitość – podobny poziom szczegółowości na równorzędnych poziomach WBS.\n6. Zorientowanie na rezultat lub działanie.\n7. Identyfikowalność - dajemy ID zadaniom.;2
Jak nazywamy liście drzewa WBS? Proszę opisać ich własności i zastosowanie w procesie planowania projektu.;Liście == pakiety pracy\nWłaściwości:\n- Są to najniższe poziomy WBS, nie dzielone już dalej.\n- Mają wyraźnie zdefiniowany zakres i rezultat (produkt lub efekt).\n- Można je oszacować czasowo i kosztowo.\n- Są przypisywane konkretnym osobom lub zespołom.\n- Umożliwiają monitorowanie postępu i kontroli jakości.\n\nZastosowanie:\n- Służą jako podstawa harmonogramu (dzielone dalej na aktywności).\n- Pomagają w tworzeniu budżetu projektu (koszty pakietów sumują się do całości).\n- Ułatwiają zarządzanie odpowiedzialnością i ryzykiem.\n- Pozwalają na śledzenie wykonania, raportowanie i rozliczanie etapów projektu.;2
Czym różni się aktywność od zadania.;Zadanie – jednostka pracy widoczna w WBS (co trzeba zrobić?).\n\nAktywność – konkretna czynność wykonywana w ramach zadania;2
Co to jest cykl życia projektu?;Uporządkowany zbiór faz, przez które przechodzi projekt od początku do końca. Opisuje strukturę i kolejność działań niezbędnych do osiągnięcia celu projektu.\n\n1. Inicjacja – określenie potrzeby, celów projektu.\n2. Planowanie – ustalenie zakresu, harmonogramu, budżetu, zasobów i ryzyk.\n3. Realizacja (wykonanie zaplanowanych zadań).\n4. Monitorowanie i kontrola zadań + korekty.\n5. Zamknięcie – rezultatt, rozliczenie projektu, dokumentacja i ewaluacja.;2
Proszę wyjaśnić różnicę pomiędzy ewolucyjnym i przyrostowym cyklem życia projektu.;Ewolucyjny cykl życia - tworzenie kolejnych, ulepszanych wersji całego systemu, stopniowo rozwijane na podstawie feedbacku - przy niejasnych wymaganiach i eksperymentach\nPrzyrostowy cykl życia - budowanie produktu przez dodawanie kolejnych działających fragmentów - przy jasnym podziale funkcji.;2
Proszę opisać spiralny cykl życia projektu.;Spiralny cykl życia - iteracyjny model łączący planowanie, analizę ryzyka, rozwój i ocenę.\nKażda spirala to kolejna faza projektu, coraz bardziej dopracowany produkt.\nKluczowe: ciągłe zarządzanie i minimalizacja ryzyka.\nStosowany przy złożonych, ryzykownych projektach z niepewnymi wymaganiami.;3
Proszę opisać kaskadowy cykl życia projektu.;Kaskadowy cykl życia to liniowy, sekwencyjny model realizacji projektu.\nEtapy następują po sobie: analiza wymagań → projektowanie → implementacja → testowanie → wdrożenie → utrzymanie.\nKażdy etap musi być zakończony przed rozpoczęciem kolejnego.\nNajlepiej sprawdza się przy dobrze zdefiniowanych i stałych wymaganiach.\nMało elastyczny, trudno wprowadzać zmiany w trakcie realizacji.;3
Proszę opisać iteracyjny cykl życia projektu.;Iteracyjny cykl życia polega na powtarzaniu kolejnych cykli pracy (iteracji).\nBasically spiralny bez nacisku na zarządzanie ryzykiem (nie to, że go niema, po prostu spiralny naciska)\nKażda iteracja zawiera fazy planowania, projektowania, implementacji i testowania.\nPo każdej iteracji powstaje działająca wersja produktu, która jest stopniowo ulepszana.\nUmożliwia szybkie wprowadzanie zmian i adaptację do nowych wymagań.\nSprawdza się przy projektach z niepełnymi lub zmiennymi wymaganiami.;3
Proszę opisać cykl życia projektu typu V.;Cykl życia typu V to rozszerzenie modelu kaskadowego z naciskiem na testowanie.\nLewa część „V” to fazy definiowania wymagań i projektowania (analiza, specyfikacja, projekt systemu).\nPrawa część „V” to fazy testowania odpowiadające każdej fazie projektowej (testy jednostkowe, integracyjne, systemowe, akceptacyjne).\nKażdy etap projektowania ma odpowiadającą fazę testów, co zapewnia wczesne wykrywanie błędów.\nModel stosowany przy projektach, gdzie jakość i zgodność z wymaganiami są kluczowe.;3
Proszę wymienić i opisać kategorie zależności pomiędzy zadaniami.;- FS - (Finish-to-Start) - Zadanie B może się rozpocząć dopiero po zakończeniu zadania A.\n- SS - (Start-to-Start) - Zadanie B może się rozpocząć dopiero gdy zacznie się zadanie A, ale nie musi czekać na jego zakończenie.\n- FF - (Finish-to-Finish) - Zadanie B może zakończyć się dopiero gdy zakończy się zadanie A.\n- SF - (Start-to-Finish) - Zadanie B może się zakończyć dopiero gdy zacznie się zadanie A (rzadko stosowana).;3
Proszę wymienić rodzaje zależności następstwa pomiędzy zadaniami i podać po jednym przykładzie z projektu IT.;Finish to Start (FS) – Przykład: Zakończenie analizy wymagań (A) ➡️ rozpoczęcie projektowania systemu (B)\nStart to Start (SS) – Przykład: Rozpoczęcie kodowania backendu (A) ➡️ rozpoczęcie kodowania frontend (B)\nFinish to Finish (FF) – Przykład: Zakończenie testów jednostkowych (A) ➡️ zakończenie testów integracyjnych (B)\nStart to Finish (SF) – Przykład: Przekazanie obowiązków ze starego systemu (B) ➡️ po uruchomieniu nowego systemu (A);3
Co to jest ścieżka krytyczna w projekcie? Jak się wyznacza ścieżkę krytyczną?;Ścieżka krytyczna - najdłuższy ciąg zależnych zadań w projekcie, który wyznacza minimalny czas jego realizacji.\n- Opóźnienie któregokolwiek zadania na ścieżce krytycznej powoduje opóźnienie całego projektu.\n\n1. Zidentyfikuj wszystkie zadania w projekcie i ich czasy trwania.\n2. Określ zależności między zadaniami (np. FS, SS).\n3. Stwórz diagram sieciowy (np. graf zależności).\n4. Oblicz najwcześniejsze możliwe rozpoczęcie i zakończenie każdego zadania (forward pass).\n5. Oblicz najpóźniejsze możliwe rozpoczęcie i zakończenie bez opóźnienia projektu (backward pass).\n6. Wyznacz zapasy czasu (float) dla każdego zadania:;3
Proszę podać charakterystykę zadań na ścieżce krytycznej.;1. Brak zapasu czasu (float = 0)\n2. Bezpośredni wpływ na czas trwania projektu - Skrócenie lub wydłużenie tych zadań zmienia datę zakończenia projektu.\n3. Najwyższy priorytet kontrolny - Wymagają szczególnej uwagi kierownika projektu\n4. Ściśle powiązane zadania\n5. Brak możliwości opóźnienia bez ryzyka;3
Proszę podać i opisać metody skracania harmonogramu.;- Crashing (przyspieszanie przez zwiększenie zasobów) - szybciej, ale większe koszty\n- Fast Tracking (równoległa realizacja zadań, które były sekwencyjne) - szybciej, ale większe ryzyko błędów;3
Jakie zastosowanie mają metryki oparte o ilość linii kodu źródłowego?;1. Szacowanie pracochłonności i kosztów - np. w COCOMO, do estymacji czasu i zasobów.\n2. Ocena produktywności zespołu - Można szacować LOC/miesiąc i porównywać zespoły\n3. Analiza złożoności projektu - Duża liczba LOC <=> większa złożoność kodu lub konieczność refaktoryzacji.\n4. Monitorowanie postępu prac - Zmiany w LOC mogą wskazywać postęp (lub regres) w implementacji.\n5. Wykrywanie potencjalnych problemów jakościowych - Zbyt duże LOC w jednym pliku może wskazywać na kod słabej jakości.;3
Proszę wyjaśnić pojęcie logicznej linii kodu.;Logiczna linia kodu (LLOC) to najmniejsza, niezależna instrukcja lub wyrażenie w kodzie źródłowym, które wykonuje określoną operację logiczną – niezależnie od liczby fizycznych linii, jakie zajmuje.\nFizyczna linia kodu (PLOC): pojedynczy wiersz w pliku źródłowym.\n\nna przykład: (kotlin) val a = 5\ val b = 10\ val c = a + b\\n3 logiczne linie\n1 fizyczna linia\n\nna przykład: (kotlin) val result = someFunction(\n    param3\n)\n1 logiczna linie\n3 fizyczne linia;4
Proszę opisać klasyczną wersję szacowania przez analogię.;Szacowanie przez analogię - metoda estymacji oparta na porównaniu nowego projektu lub zadania do wcześniejszych, podobnych przypadków, dla których znany jest rzeczywisty czas, koszt lub wysiłek.\n\n1. Identyfikacja podobnych projektów/zadań z przeszłości – najlepiej z tej samej organizacji lub domeny.\n2. Porównanie cech (rozmiar, złożoność, technologia, zespół) – oceniana jest podobieństwo na podstawie np. liczby funkcji, typów modułów, użytych technologii.\n3. Dostosowanie szacunków – jeśli nowy projekt jest większy/mniejszy lub bardziej złożony, wprowadza się korekty.\n4. Przyjęcie wartości jako estymacji;4
Proszę wyjaśnić metodę szacowania z wykorzystaniem logiki rozmytej.;Logika rozmyta - uwzględnienie niepewności i nieprecyzyjności w szacowaniu. Użyte gdy dane wejściowe są twardymi liczbami (np. "średnio trudne", "raczej czasochłonne").\nWymaga większej ilości danych historycznych\n\nOkreślenie cech projektu w sposób językowy (rozmyty) - np. niska złożoność, średnie ryzyko, duże doświadczenie zespołu.\nZamiana tych ocen na wartości liczbowe - użycie funkcji przynależności (np. średnia trudność = 0.6 w skali 0–1).\nZastosowanie reguł logiki rozmytej:\n   - Jeśli projekt jest złożony i zespół ma małe doświadczenie, to czas = długi\n   - Jeśli projekt jest prosty i zespół doświadczony, to czas = krótki\nAgregacja wyników – po zastosowaniu reguł, otrzymujemy zbiór rozmyty jako wynik.\nDefuzyfikacja (ostateczny wynik) - Zbiór rozmyty przekształcany jest na konkretną wartość, np. szacowany czas = 145 godzin.;4
Proszę wyjaśnić metodę szacowania z wykorzystaniem składników standardowych.;4To systematyczna metoda estymacji -dzielenie projektu na powtarzalne, wcześniej zdefiniowane elementy (składniki standardowe), dla których znamy przybliżony koszt, czas lub wysiłek.\n\n1. Zdefiniowana jest baza składników standardowych\n    – np. formularz rejestracji, raport PDF, ekran logowania, CRUD do bazy danych.\n    – Dla każdego składnika znamy: czas pracy, koszt, ryzyko, złożoność.\n\n2. Analizujemy projekt i identyfikujemy składniki\n    – np. projekt zawiera: 2 raporty PDF, 3 formularze, 1 panel admina.\n\n3. Zliczamy i sumujemy jednostkowe estymacje\n    – np. raport PDF = 20 godzin → 2 raporty = 40 godzin\n\n4. Dodajemy rezerwę na integrację, testy, ryzyko itp.;4
Proszę wyjaśnić metodę szacowania z wykorzystaniem składników standardowych z percentylami.;Rozwinięcie metody składników standardowych - uwzględnia zmienność czasów realizacji składników na podstawie danych historycznych – poprzez użycie percentyli.\n\n1. Zbierasz dane historyczne dla składników standardowych:\n    np. ile godzin zajmowało przygotowanie formularza w przeszłych projektach.\n\n2. Obliczasz percentyle czasów realizacji dla każdego składnika:\n    np. dla składnika "formularz":\n        P25 (optymistycznie): 10h\n        P50 (średnio): 14h\n        P75 (pesymistycznie): 18h\n\n3. Dla nowego projektu wybierasz poziom pewności (percentyl)\n    – np. P50 jeśli zakładasz typowe warunki,\n    – P75, jeśli spodziewasz się ryzyk i chcesz bufor.\n\n4. Estymujesz projekt jak w klasycznej metodzie, ale używasz wartości z wybranego percentyla.;4
Proszę wyjaśnić metodę szacowania przez punktację historyjek.;W metodykach zwinnych (np. Scrum), oparta nie na czasie, lecz na ocenie złożoności i wysiłku danego zadania (historyjki użytkownika).\n\n1. Historyjkom użytkownika (ang. user stories) przypisuje się punkty (story points), np. 1, 3, 5, 8…\n2. Punkty oznaczają względną wielkość, która uwzględnia:\n    – złożoność techniczną\n    – ilość pracy\n    – ryzyko / niepewność\n3. Zespół porównuje nowe historyjki do wcześniejszych, już zrealizowanych.\n4. W kolejnych sprintach zespół mierzy swoją prędkość (velocity), czyli ile punktów średnio realizuje w jednym sprincie.;4
Proszę wyjaśnić metodę szacowania rozmiarami.;Najpierw określa się rozmiar produktu lub jego części, a potem przelicza się go na czas, koszt lub wysiłek.\n1. Określenie jednostki rozmiaru\n    – np. liczba funkcji, ekranów, przypadków użycia, linii kodu, Function Points (FP), LOC itp.\n\n2. Oszacowanie całkowitego rozmiaru systemu\n    – ile funkcjonalności, ile ekranów, ile zapytań do bazy itd.\n\n3. Przeliczenie rozmiaru na wysiłek\n    – na podstawie wcześniejszych projektów lub norm wydajnościowych\n    – np. 1 Function Point = 5 roboczogodzin → 100 FP = 500 godzin;4
Proszę wyjaśnić pojęcie produktywności w odniesieniu do metod szacowania przez analogię.;Produktywność oznacza średni wysiłek (np. czas, roboczogodziny) potrzebny do wykonania jednostki podobnego produktu lub zadania.\n\n1. Wybieramy analogiczny projekt lub zadanie, które zostało wcześniej zrealizowane.\n2.Znana jest jego wielkość (np. liczba funkcji, Function Points, LOC) i czas realizacji.\n3. Produktywność = wysiłek / rozmiar;4
Proszę opisać metodę PERT. Dlaczego PERT opiera się na rozkładzie trójkątnym?;Metoda PERT (Program Evaluation and Review Technique) - technika szacowania czasu trwania zadań, która uwzględnia niepewność i ryzyko. \n\nKażde zadanie opisuje się trzema czasami:\n    - Optymistyczny (O) – jeśli wszystko pójdzie idealnie\n    - Pesymistyczny (P) – jeśli wystąpią trudności\n    - Najbardziej prawdopodobny (M) – jeśli projekt przebiega typowo\n\nWzór na czas oczekiwany (średni):\n- E=(O + 4M + P) / 6 - przy rozkładzie Beta (sugerowanym)\n- E=(O +  M + P) / 3 - przy rozkładzie trójkątnym - gdy jest mało danych statystycznych lub gdy dane są subiektywne;4
Jak obliczyć czas realizacji projektu dla zadanego z góry prawdopodobieństwa sukcesu?;Aby wyznaczyć czas ukończenia projektu przy określonym prawdopodobieństwie (np. 90%), stosuje się statystykę rozkładu normalnego\n(Zakładając, że czasy trwania ścieżki krytycznej mają charakter rozkładu normalnego)\n\n1. Dla każdego zadania na ścieżce krytycznej:\n    Oszacuj czasy:\n        O – optymistyczny\n        M – najbardziej prawdopodobny\n        P – pesymistyczny\n    Oblicz:\n        średni czas (wartość oczekiwana):\n            TE=(O+4M+P)/6\n\n        wariancję zadania:\n            VAR=( (P − O) / 6 )^2\n\n2. Zsumuj średnie czasy zadań na ścieżce krytycznej (TE_projektu == oczekiwany czas trwania projektu).\n\n3. Zsumuj wariancje zadań na ścieżce krytycznej (wariancja całkowita) (VAR_projektu), a pierwiastek z niej to odchylenie standardowe σ.\n\n4. Ustal prawdopodobieństwo sukcesu (np. 90%) i znajdź odpowiedni z-score z tabeli rozkładu normalnego:\n    99% → z ≈ 2.33\n\n5. Oblicz czas potrzebny do osiągnięcia tego prawdopodobieństwa:\n\nT=TE_projektu + z * σ;4
Proszę opisać model podstawowy COCOMO (81).;COCOMO - Constructive Cost Model\nMetoda szacowania kosztów opierająca się na fenomenologicznych zależnościach:\n    - wielkość projektu <-> koszt projektu\n    - koszt projektu <-> czas trwania projektu\n\nTrzy poziomy hierarchii COCOMO:\n     - Podstawowy\n     - Pośredni\n     - Szczegółowy\n\nRodzaje projektów w Podstawowym COCOMO:\n    - Łatwe (organic) – małe, proste projekty z małym zespołem (2-4 osoby), z dobrze określonymi, stałymi wymaganiami\n    - Średnie (semi-detached) – średniozaawansowany zakres i średnia złożoność, brak wiedzy o części wymagań, brak wiedzy o części technologii\n    - Trudne (embedded) – silne ograniczenia technologiczne i procesowe, duży poziom nieoznaczoności, state of art\n\nSzacowany wysiłek (person-months):\n    Effort = a * (KLOC^b)\nSzacowany czas trwania (miesiące):\n    Time = c * (E^d)\nLiczba zasobów\n    Resources = Effort / Time\nKoszt całkowity:\n    Cost = Effort * koszt roboczogodziny\n\na, b, c, d zależą od typu w Podstawowym COCOMO;5
Czym różni się model podstawowy COCOMO od szczegółowego?;1. podstawowy szybszy, ale szczegółowy dokładniejszy\n2. szczegółowy dodatkowo potrzebuje dane o czynnikach kosztowych (jakość zespołu, złożonośc)\n3. podstawowy analizuje cały projekt, a szczegółowy wchodzi w konkretne moduły\n4. podstawowy niska elastyczność, a szczegółowy wysoka bo wchodzi w konkretne moduły\n5. podstawowy wstępna estymacja, a szczegółowy po głębszym poznaniu projektu;5
Proszę podać definicję metryki punktów funkcyjnych. Jakie cele ma analiza punktów funkcyjnych?;Miara wielkości oprogramowania oparta na funkcjonalnościach dostarczanych użytkownikowi,1 niezależna od technologii czy języka programowania.\nOkreślają ilość funkcji, które system musi wykonać z perspektywy użytkownika.\n\nCele analizy punktów funkcyjnych:\n    - Szacowanie rozmiaru projektu – niezależnie od technologii\n    - Porównywanie projektów – pozwala porównać różne systemy lub wersje\n    - Planowanie i kontrola kosztów oraz czasu\n    - Wspomaganie zarządzania jakością i produktywnością\n    - Podstawa do analiz efektywności i benchmarkingu;5
Proszę opisać proces estymacji za pomocą analizy punktów funkcyjnych.;1. Określenie rodzaju punktów funkcyjnych: (jakie typy punktów funkcyjnych będą brane pod uwagę w analizie).\n2. Zdefiniowanie granicy systemu\n3. Identyfikacja kategorii funkcyjnych\n4. Policzenie funkcji danych. Są to logiczne pliki wewnętrzne (ILF) oraz zewnętrzne pliki interfejsowe (EIF), które reprezentują dane przechowywane lub używane przez system.\n5. Policzenie funkcji transakcyjnych: czyli funkcji które przetwarzają dane. Obejmują one wejścia (EI), wyjścia (EO) i zapytania (EQ).\n6. Ocena złożoności ograniczeń niefunkcyjnych: (np. wydajność, bezpieczeństwo, użyteczność) na ogólną złożoność systemu. Może wpływać na liczbę FP\n7. Obliczenie zmodyfikowanych punktów funkcyjnych;5
Proszę wymienić i opisać rodzaje punktów funkcyjnych.;Funkcje Danych:\n    - (ILF) Wewnętrzne Pliki Logiczne : Dane utrzymywane i kontrolowane przez system.\n    - (EIF) Zewnętrzne Pliki Interfejsowe : Dane używane przez system, ale utrzymywane przez system zewnętrzny.\n\nFunkcje Transakcyjne:\n    - (EI) Wejścia (EI): odbierania danych spoza systemu.\n    - (EO) Wyjścia (EO): generowania danych i wysyłania ich poza system.\n    - (EQ) Zapytania (EQ): odbierania danych z systemu i zwracania informacji.;5
Proszę podać znane definicję jakości oprogramowania.;Podejście producenta:\n    - "Zgodność z wymaganiami" – Crosby (1979)\n    - "Przydatność do użytku" – Juran i Gryna (1970)\n\nPerspektywa klienta:\n"Twoi klienci są w stanie świetnie opisać jakość produktu, ponieważ ją właśnie tak naprawdę kupują. Nie kupują produktu. Kupują zapewnienie, że produkt spełni ich oczekiwania" – Guaspari (1985)\n\nDefinicje jakości:\n    - Wąska: częstość defektów lub niezawodność systemu\n    - Szeroka: pomiar satysfakcji klienta (ankiety);5
Proszę podać definicję metryki częstości defektów wraz z przykładem.;Definicja:\n`Częstość defektów = Liczba defektów / OFE (Opportunities for Error)`\n\nOFE może być:\n    - Liczba linii kodu (KLOC)\n    - Punkty funkcyjne (FP)\n\nPrzykładowe wartości dla CMM (Capability Maturity Model ?):\n| Poziom CMM | Defekty/FP |\n|------------|------------|\n| Poziom 1   |       0,75 |\n| Poziom 2   |       0,44 |\n| Poziom 3   |       0,27 |\n| Poziom 4   |       0,14 |\n| Poziom 5   |       0,05 |;5
Proszę podać definicję metryki częstości defektów w testach maszynowych. Proszę wyjaśnić jak należy interpretować otrzymywane wartości tej metryki.;Definicja: Liczba błędów na KLOC wykrytych w automatycznych testach.\n\nInterpretacja zmian wartości (slajd 271):\n\nJeżeli liczba defektów się zmniejszyła:\n    - Pytanie: Czy testy były tak samo dokładne?\n    - Jeśli TAK → test pozytywny, poprawa jakości\n    - Jeśli NIE → konieczne dodatkowe testy\n\nJeżeli liczba defektów wzrosła:  \n    - Pytanie: Czy rzeczywiście poprawiliśmy efektywność testów?\n    - Jeśli NIE → prognoza jakości negatywna, potrzeba dodatkowych testów\n    - Jeśli TAK → utrzymać aktualne testy, lepsza wykrywalność;5
Proszę podać definicję metryki efektywności usuwania defektów. Proszę opisać przykładowe zastosowanie.;Wzór Dunna (1987) (slajd 274):\n`E = N/(N + S)`\n\nGdzie:\n    - E = efektywność czynności dla danej fazy\n    - N = liczba defektów znalezionych w danej fazie  \n    - S = liczba defektów znalezionych w następnych fazach\n\nPoziomy efektywności według CMM (slajd 279):\n    - CMM 1: 85%\n    - CMM 2: 89%  \n    - CMM 3: 91%\n    - CMM 4: 93%\n    - CMM 5: 95%;5
Proszę opisać statyczny model niezawodności oprogramowania.;Definicja (slajdy 288-291): Model bazujący na rozkładzie Weibulla z parametrem m=2.\n\nFunkcja gęstości:\n`f(t) = (2K/c²) × t × e^(-(t²/c²))`\n\nParametry:\n    - K – całkowita liczba defektów (lub łączna częstość defektów)\n    - c – czas, po którym funkcja osiąga maksimum (szczyt wykrywania defektów)\n    - t – czas (faza projektu lub miesiąc)\n\nZastosowania:\n    - Opis tempa wykrywania błędów w kolejnych fazach\n    - Oszacowanie ukrytych defektów przed release\n    - Planowanie kosztów serwisu na podstawie przewidywanej liczby defektów\n    - Założenie: Częstość defektów wykrytych w produkcji koreluje z defektami operacyjnymi\n\nPodstawowe założenie modelu: Im więcej defektów wykrytych wcześniej, tym mniej defektów na końcu procesu.\n\n[Uzupełnienie - wiedza ogólna]: Model Rayleigha jest szczególnie użyteczny w fazie testowania, gdzie maksimum krzywej często przypada na okres testów systemowych. Parametr 'c' pozwala przewidzieć, kiedy tempo wykrywania defektów zacznie spadać, co jest sygnałem zbliżania się do gotowości produktu do wydania.;5